{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一.创建tensor的方法\n",
    "1.torch.Tensor(),torch.Tensor([[1,2],[3,4]])\n",
    "\n",
    "2.torch.eye():创建对角线全1，其余全零的tensor\n",
    "\n",
    "3.torch.zeros(),torch.zeros_like():参数为一个tensor\n",
    "\n",
    "4.随机生成 torch.rand():生成服从[0,1)均匀分布的tensor，torch.randn()：生成服从标准正态分布的tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from random import uniform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor value from different nor dis:torch.FloatTensor\n",
      "tensor([  2.6642, 108.6001, 988.1343])\n"
     ]
    }
   ],
   "source": [
    "# torch.normal()\n",
    "x_dif_nor=torch.normal(mean=torch.Tensor([1.,100.,1000.]),std=torch.Tensor([1.,10.,20.]))\n",
    "print('tensor value from different nor dis:{0}\\n{1}'.format(x_dif_nor.type(),x_dif_nor))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Tensor.uniform_():用符合[a,b]间均匀分布的值填充tensor\n",
    "将tensor使用符合[a,b)间均匀分布的值填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_uniform:torch.FloatTensor\n",
      "tensor([[228.1739, 233.7821, 299.7418],\n",
      "        [257.6478, 291.7734, 206.1416]])\n"
     ]
    }
   ],
   "source": [
    "x_uniform_=torch.Tensor(2,3).uniform_(200,300)\n",
    "print('x_uniform:{0}\\n{1}'.format(x_uniform_.type(),x_uniform_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成序列tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.arange(a,b,step)，[a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_arange:torch.LongTensor\n",
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "x_arange=torch.arange(0,10,2)\n",
    "print(\"x_arange:{0}\\n{1}\".format(x_arange.type(),x_arange))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.linspace(a,b,num)\n",
    "生成将[a,b]切分成num份后，由切分点组成的tensor，默认floatTensor类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_linspace:torch.FloatTensor\n",
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "x_linspace=torch.linspace(0,9,10)\n",
    "print('x_linspace:{0}\\n{1}'.format(x_linspace.type(),x_linspace))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "torch.randperm(n)\n",
    "生成将[0,1,...,n]随机打乱后的tensor，默认类型LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_randperm:torch.LongTensor\n",
      "tensor([8, 4, 7, 5, 3, 2, 0, 1, 9, 6])\n"
     ]
    }
   ],
   "source": [
    "x_randperm=torch.randperm(10)\n",
    "print(\"x_randperm:{0}\\n{1}\".format(x_randperm.type(),x_randperm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二.tensor操作\n",
    "\n",
    "加法操作\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2284, 1.3076, 1.0135],\n",
      "        [0.1782, 1.2059, 1.0859],\n",
      "        [0.8393, 0.4367, 0.6118],\n",
      "        [0.4847, 1.2364, 1.6209],\n",
      "        [0.7609, 0.6102, 1.7849]])\n",
      "tensor([[1.2284, 1.3076, 1.0135],\n",
      "        [0.1782, 1.2059, 1.0859],\n",
      "        [0.8393, 0.4367, 0.6118],\n",
      "        [0.4847, 1.2364, 1.6209],\n",
      "        [0.7609, 0.6102, 1.7849]])\n",
      "tensor([[1.2284, 1.3076, 1.0135],\n",
      "        [0.1782, 1.2059, 1.0859],\n",
      "        [0.8393, 0.4367, 0.6118],\n",
      "        [0.4847, 1.2364, 1.6209],\n",
      "        [0.7609, 0.6102, 1.7849]])\n"
     ]
    }
   ],
   "source": [
    "y=torch.rand(5,3)\n",
    "x=torch.rand(5,3)\n",
    "print(x+y)\n",
    "\n",
    "result=torch.empty(5,3)\n",
    "torch.add(x,y,out=result)\n",
    "print(result)\n",
    "\n",
    "y=y.add_(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "索引：访问tensor的一部分\n",
    "索引出来的结果与原数据共享内存。\n",
    "\n",
    "https://blog.csdn.net/qimo601/article/details/112185073?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166692825416782388073353%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=166692825416782388073353&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-1-112185073-null-null.142^v62^pc_rank_34_queryrelevant25,201^v3^control_2,213^v1^control&utm_term=tensor%E7%B4%A2%E5%BC%95&spm=1018.2226.3001.4187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6541,  0.9316, -0.0453, -0.2143],\n",
      "        [-0.8074,  1.5196, -0.0513, -1.0349],\n",
      "        [-0.5436, -0.3675,  0.9124,  0.2017]])\n",
      "tensor([ 0.6541,  0.9316, -0.0453, -0.2143])\n",
      "tensor([ 0.6541, -0.8074, -0.5436])\n",
      "tensor(0.6541)\n",
      "tensor(-0.2143)\n",
      "tensor([[ 0.6541,  0.9316, -0.0453, -0.2143],\n",
      "        [-0.8074,  1.5196, -0.0513, -1.0349]])\n",
      "tensor([[ 0.6541,  0.9316],\n",
      "        [-0.8074,  1.5196]])\n",
      "tensor([[0.6541, 0.9316]])\n",
      "tensor([0.6541, 0.9316])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(3,4)\n",
    "print(a)\n",
    "print(a[0]) #第零行\n",
    "print(a[:,0]) #第零列\n",
    "print(a[0][0]) \n",
    "print(a[0,-1]) #第零行最后一个数字\n",
    "print(a[:2]) #前两行\n",
    "print(a[:2,0:2]) #前两行的前两列\n",
    "print(a[0:1,:2]) #第零行前两列\n",
    "print(a[0,:2]) #区别？\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n",
      "15\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.arange(15)\n",
    "print(x.shape)\n",
    "# tensor形状\n",
    "print(x.numel())\n",
    "# tensor元素总数\n",
    "X=x.reshape(5,3)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改变形状 view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]) tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14]]) torch.Size([15]) torch.Size([15]) torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "from cgi import print_arguments\n",
    "\n",
    "\n",
    "y=x.view(15)\n",
    "z=x.view(-1,5)  #-1所指维度可以根据其他维度值推测出来\n",
    "print(y,z,x.size(),y.size(),z.size())"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "原始单元格格式",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "086b3500db1d66433b7f6c6ed2d29527e36597aa4abc1b3e2cae9a7bdecb333b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
